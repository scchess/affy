\documentclass[a4paper, 11pt]{article}

\usepackage{hyperref}
\usepackage[dvips]{graphicx}

\title{NOTES ON AFFY PACKAGE}

\author{Laurent Gautier, Rafael A. Irizarry, Leslie Cope}
%\author{Rafael A. Irizarry, Laurent Gautier, Leslie Cope}
% :-)

% erh... I copied that blindly from a .Rnw in Biobase but I am not sure it is usefull
\newcommand{\classdef}[1]{%
  {\em #1}
}

\begin{document}

\maketitle

\section{Introduction}
The package results from the fusion of simultaneous efforts. When he became aware of the existence of {\it an another one},
an author offered to collaborate (after a quick and approximate survival analysis). The union of the names of the different packages
was kept as a new name.

We created a package of functions dedicated to the analysis of the data obtained by the use of the {\it Affymetrix} technology.
The aim is to provide a complete and flexible environment. Emphasis was put on letting the user go beyond the defined functions
by creating his own, and integrate them together to create one's own way of processing the data.
An easy access to the statistical and graphical facilities is garanteed by the powerful R machinery.
Some of the examples given in this manual show particularities of the data that are not known to have been studied, some are
just artificial examples to demonstrate how curiosity can get satisfied (or aroused) in few lines of code.
The impatient user will directly refer to the section~\ref{sec:kickstart}, page~\pageref{sec:kickstart}.

While the present system does not pretend to compete in term of speed or data warehousing with dedicated programms, it is thought
to have its strength with flexibility, adaptability, and accessibility. The present package was
release under the GPL license, which garanties the availability of the source in its present stage and in the further developments.

This manual will present the classes and methods in detail in a first part.
The second part will follow what we thought being a logical sequence of operations and observations of the
data. We distinguished four main parts: visual inspection, normalization,
expression value generation from sets of probe pairs and
statistical analysis. As much as possible, we include snippets of R code to demonstrate the concision
of the statements needed to perform a task. We also include the results obtained
and discussed them further.
Examples were kept as much as possible as standalone pieces.

The last part shows how a complete data processing workflow can be implemented.

All the functions of the package could not be described in this documentation.
However, they all have an help page than can be accessed through R.

We assume that the reader is already familiar with oligonucleotide arrays and with the
particularities in the design of the arrays by the manufacturer. The following term are used
throughout this document with a specific meaning.
\begin{description}
  \item[probe] a thinggy on the array
  \item[perfect match] probe supposed to match perfectly the target sequence.
  \item[mismatch] the probe supposed to have a base mismatch with the target sequence.
  \item[probe pair] a unit consitituted of the corresponding perfect match and mismatch.
  \item[affyID] an identification for a gene or a fraction of a gene on the array.
  \item[probe pair set] several probes relating to a common affyID.
\end{description}
% Quote the book chapter somewhere. It should have more examples and be more complete.

The installation is straigtforward.
On Unices:
\begin{verbatim}
R CMD INSTALL affy.tar.gz
\end{verbatim}

On MS Windows
\begin{verbatim}
XXX ?
\end{verbatim}

The package relies on the presence of other packages or on the presence of external libraries for some of its
funcionalities. More specifically:
\begin{enumerate} 
 \item The library {\it zlib} is required to read through compressed files with the
functions \verb+read.cdffile+ and \verb+read.celfile+
 \item The R package \verb+methods+ is required for almost anything to work
 \item The R package \verb+Biobase+ is required for almost anything to work too.
 \item The R package \verb+modreg+ is required for some of the normalization routines
 \item The R package \verb+tcltk+ is required for the functions involving GUI.
\end{enumerate}
The command \verb+library()+ within an R console will list the package installed.
The missing packages can be downloaded from the {\it CRAN} website ({\it http://www.r-project.org/}) or from the
{\it bioconductor} website ({\it http://www.bioconductor.org/}).

\section{Classes}

Objects can be used to model actors of a process, and let one interact with it an reasonably intuitive way.
The package benefited from important efforts in this sense. We hope we made it quickly usable and extendable.

The relatively new system of classes in R (called the S4 system) was widely used in the package. The next few lines
will introduce a limited number of elements relative to it. It should be able to enable users whom the S4 system is not
known to proceed through this document. More advanced knowledge of the system will probably needed for an advanced use
of the functionalities of the package. An instance of a class is a XXX. 
For an instance \verb+a+ of a class \verb+MyClass+ having a attribute called \verb+myAttribute+, one can access the
attribute simply by writing \verb+a@myAttribute+.
For the most common attributes, accessor methods are built in the class. Using the previous example, we would have an accessor
function \verb+myAttribute+ applied to the instance \verb+a+: verb+myAttribute(a)+ .

Different classes have been implemented in the package to ease the manipulation of the data. The main ones are described below,
with a note for their main verb+slots+ and verb+methods+.
Users who are already familiar with the different categories of files involved in the analysis will not be surprised to find
classes corresponding to the \verb+Cdf+ and \verb+Cel+ files.

  \subsection{Cdf-class}

The {\it Chip Definition Files} ({\it CDF} files) are used to store informations related to
a type of oligonucleotide array sold by the manufacturer. All the arrays belonging to a given type will share this same information.
As the quantity of informations in a {\it CDF} can be rather large, this is an important point. This is kept in the design of the package,
as there will be only one verb+Cdf+ object in memory, to which will refer the corresponding \verb+Cel+ files.

For instance when during an experiment a total of 30 arrays of type {\it Hu6800} are used, the information relative the array type is
common to all the chips. Knowing that a {\it CDF} files weights 20 Megabytes, will help to realize the interest of avoiding to repeat this information.
A summary of the slots can be found in the table~\ref{table:Cdf}.

\begin{description}
 \item[name] Each {\it probe} (or {\it feature}) on an array is an oligonucleotide from a larger sequence of nucleic acids 
(generally a gene or a fraction of a gene), we refer to as a probe pairs set (XXX see PPSet).
 All these {\it large sequences} were given a unique name by the chip manufacturer. By design of the arrays severals probes correspond to different
parts of the same larger sequence, hence have the same name. Names are stored as factors, and the corresponding factors labels (or levels) are found in the
attribute \verb+name.levels+.

Example:
%\vignette{Cdf-class}
<<>>= 
  library(affy)

  data(CDF.example)

  geneid <- "D13640_at"
  ## look for the position of the factor label "D13640_at"
  i <- match(geneid, CDF.example@name.levels)
  ## (it holds the integer value 43)

  ## look for the corresponding name(s)
  genepos <- which(CDF.example@name == i, arr.ind=TRUE)
  ## genepos holds the x,y's corresponding to "D13640_at"
  ## the function locate.name() is working this way.
@
%\end{verbatim}

 \item[name.level]
 \item[pbase] In the {\it CDF} files, the column called {\it PBASE} holds one of the nucleic acid letters. From trials and errors
\footnote{Comparing the letter between {\it PBASE} and {\it TBASE}, it appeared that two cases could appear. }
, the {\it p} was guessed
 to stand for {\it probe}.
 \item[pbase.levels] The four levels for \verb+pbase+ are the four letters used to designatee nucleic acids.
 \item[tbase] In the {\it CDF} files, the column called {\it TBASE} holds also a nucleic acid letter. From trials and errors where the {\it t}
 was assumed to stand for {\it tbase}.
 \item[tbase.levels] The four same letters than for \verb+pbase.levels+ are found here.
 \item[atoms] Each {\it probe pair} (XXX make sure this term has been defined earlier) in a probe pair set is given a unique integer as an indentifier.
This number is refered as the {\it atom} number. The corresponding {\it perfect matches} and {\it mismatches} are found by using this number.

Example:
%\vignette{Cdf-class}
<<>>= 
  data(CDF.example)

  ## store in x the size of the probe pair sets
  ## (there are two atoms per pair, so we divide per 2)
  x <- tapply(CDF.example@atom, CDF.example@name, FUN=length) / 2
  dimnames(x) <- list(CDF.example@name.levels[as.integer(names(x))])
  
  ## select the probe pairs with less than 5 probe pairs
  s <- which(x < 5)
  
  x[s]
  
  ## note: these probe pair sets mostly exist because example.CDF
  ## is an artificial data set.
  ## (which is a corner of a Hu6800 chip).
@
%\end{verbatim}
\end{description}

\subsection{class Cel}

Objects of class \verb+Cel+ contain the informations held in {\it CEL} files.

It was decided to use matrices to store the data. The lookup of values at particular
positions on the chip becomes extremely easy.

\begin{figure}[h]
   \label{fig:image}
   \begin{center}
     \includegraphics[scale=.6,angle=0]{gridcel.ps}
   \end{center}
   \caption{The data matrix used to store the data can be thought of as a grid. Knowing the position of probes on the grid, finding the values
for them is done by indexing the corresponding elements.}
\end{figure}

The combination of the \verb+Cel+ and the \verb+Cdf+ allows to extract XXXblabla any kind of informations XXX.
The choices in the design might be considered awkward, as the resulting data structure can be perceived as more
 complex. It should not turn away the novice user.
Objects of class \verb+Plob+ (see~\ref{subsection:Plob}, page~\pageref{subsection:Plob}) have a different
data structure and can be an alternative. A convenience function to shuttle between the data structure can be
found in the package (try \verb+help(convert)+ in R). 

\begin{description}
  \item[image]
  \item[show]
\end{description}

\subsection{class Cel.container}

The class \verb+Cel.container+ extends the class \verb+container+ of the package {\it Biobase}. It allows to bundle a collection of \verb+Cel+ instances
together. Typically, a \verb+Cel.container+ will contain \verb+Cel+ instances sharing the same \verb+Cdf+
% \footnote{We plan to have
%a link to the \verb+Cdf+ included in \verb+Cel.container+... probably in the next version...}.

\begin{description}
  \item[generateExprSet] Compute expression values and return them in an \verb+exprSet+ object.
  \item[normalize] A \verb+Cel.container+ can be {\it normalized}, which means its \verb+Cel+ elements will be scaled to be comparable. More details about normalization can be found in the section~\ref{sec:normalize}, page~\pageref{sec:normalize}.
  \item[normalize.methods] Return the known normalization methods for the \verb+Cel+.
  \item[show] Display global information about the object
\end{description}

\subsection{class PPSet}

\begin{description}
  \item[probes] a data frame having two column named {\it pm} and {\it mm} respectively. 
  \item[name] the name of the probe pair set
\end{description}

\begin{description}
  \item[show]
  \item[barplot]
  \item[plot]
\end{description}


\subsection{class PPSet.container}

\begin{description}
  \item[show]
\end{description}

\subsection{class Plob}

The class \verb+Plob+ represents an another view on the data. One could think of it as related to the class \verb+Cel.container+
as it contains most of the information contained in it. It also contains informations from the corresponding CDF file. The data
are organised in a different structure. We think of it as an another point of view on the data. It can be more convenient .

%>>>LG: RAFA: HELP for below!!!

\begin{description}
  \item[normalize] 
  \item[normalize.methods] Return the known normalization methods for the \verb+Cel+.
  \item[show] Display global information about the object
\end{description}

\subsection{Summary tables for the classes}
The tables below show the main classes with their slots and methods that we thought being of prime importance.
Comprehensive description of the classes can be found in the help files.


\begin{tabular}{|p{3.5cm}|p{8cm}|}
%\label{table:Cdf}
\hline
\multicolumn{2}{|l|}{\textbf{Class Cdf - slots}}\\
\hline
name & matrix of 'factors' for the gene names corresponding to the probes.\\
name.levels & the levels corresponding to the `name'. \\
pbase & matrix of 'factors' of pbases.\\
pbase.levels & the corresponding levels.\\
tbase & matrix of 'factors' of tbases.\\
tbase.levels & the corresponding levels.\\
atom & matrix of atom numbers.\\
\hline
\end{tabular} 

\begin{tabular}{|p{3.5cm}|p{8cm}|}
%\label{table:Cel}
\hline
\multicolumn{2}{|l|}{\textbf{Class Cel - slots}}\\
\hline
name & the name given to this CEL file data... the file name by default.\\
intensity & intensity values in a matrix of dimension (nrow,ncol)\\
sd & standard deviation for the intensity values (as they are
    included in the CEL files there might be a use for them).\\
masks & \\
outliers & \\
history & a list. Informations about the nature of the data.\\
\hline
\multicolumn{2}{|l|}{\textbf{methods}}\\
\hline
image & Display the intensities in the \verb+Cel+ according to their spatial locations.\\
show & \\
\hline
\end{tabular} 

\begin{tabular}{|p{3.5cm}|p{8cm}|}
%\label{table:Cdf}
\hline
\multicolumn{2}{|l|}{\textbf{Class Plob - methods}}\\
\hline
normalize & \\
normalize.methods & \\
show & \\
\hline
\end{tabular} 

\begin{tabular}{|p{3.5cm}|p{8cm}|}
%\label{table:Cdf}
\hline
\multicolumn{2}{|l|}{\textbf{Class PPSet - methods}}\\
\hline
show & \\
barplot & \\
plot & \\
\hline
\end{tabular}

\begin{tabular}{|p{3.5cm}|p{8cm}|}
%\label{table:Cdf}
\hline
\multicolumn{2}{|l|}{\textbf{Class PPSet.container - methods}}\\
\hline
show & \\
\hline
\end{tabular} 

\section{Overview of steps in the data processing/data analysis}

 \subsection{Kicktart}
\label{sec:kickstart}
The impatient has urgent need for results, but intends to read the rest of the documentation later. Convenience
functions allow to go from the \emph{Affymetrix} CEL and CDF data files to expression values without having to
be preoccupied by the intermediate steps. They reflect recent work about the processing of probe level data
%>>>LGL: Hey, Rafael I intend to quote your paper here, update on the refs please. Has it been submitted
 and provide what we believe a good way to obtain expression values.

The function are \verb+ReafAffy+ and \verb+express+. The script will be as simple as:
\begin{verbatim}
Data <- ReadAffy()
E <- express(Data)
\end{verbatim}
%>>>LG: is the GUI ready ? would be better here...
The object E is of class \verb+exprSet+ (defined in the package \emph{Biobase}). A way to dump the expression
values in a file where columns are separated by tabulations is:
\begin{verbatim}
write.table(exprs(E), file="ny/output/file.txt", sep="\t")
\end{verbatim}

 \subsection{Visual control}

 \subsection{image}
A first example shows how one can observe the physical location of the values contained in a CEL file 

In the absence of {\it CEL} files, example can be used.
%\vignette{image.Cel}
<<>>=
library(affy)
data(listcel)
mycelfile <- listcel[[1]]
@
%\end{verbatim}
If a {\it CEL} file is available, the previous lines can be replaced by
\begin{verbatim}
mycelfile <- read.celfile("path/to/my/celfile")
\end{verbatim}
or if the \verb+tcltk+ library is available, the {\it CEL} file can be picked with the mouse by using
%>>>LG EXAMPLE !!!
XXX

The example below presents the method \verb+image+.

%\vignette{image.Cel}
<<fig=TRUE>>=
opar <- par
par(mfrow=c(2,2))
image(mycelfile, sub="raw values")
image(mycelfile, col=rainbow(32), sub="raw values")
image(mycelfile, transf=log, sub="log-transformed values")
image(mycelfile, transf=log, col=rainbow(32), sub="log-tranfomed values")
par <- opar
@
%\end{verbatim}


 \subsection{Normalization}
\label{sec:normalize}
An important issue in microarray data analysis is to adjust the signal obtained from different arrays in order to make them
comparable. The technical particularities of the different approaches will only be outlined here.
The reader will refer to XXX (ref!) for more details.


Different approaches to normalize array data have been suggested. New methods are very likely be developped too, so
addition of new normalization methods should be straightforward.
It should be the case if the following indications are carefully observed.
Brave people may want to add new normalization methods without taking these rules into considerations. 
It should be possible, but they are on their own.
\begin{itemize}
 \item[-] Normalization method must obey a naming convention. The name of the function should be like \verb+normalize.XYZ.abc+,
where \verb+abc+ is the {\it nickname} of the method and \verb+XYZ+ is the name of the object the normalization methods works on.
Currently XYZ can only be \verb+Cel.container+ or \verb+Plob+\footnote{A general scheme for normalization of arrays, whether
{\it Affymetrix} or cDNA (or even others in the future (?)) is currently evaluated.}
 \item[-] The first argument passed to the function must be of class \verb+XYZ+. Optional parameter can be appended as long
as they have default values./
 \item[-] The {\it nickname} of the new normalization method must be registered in the variable \verb+normalize.XYZ.methods+
 (a vector of mode {\it character}).
\end{itemize}

The following example shows how to create a normalization methods that does... absolutely nothing:

%\begin{vignette}
<<>>=
normalize.Cel.container.nothing <- function(object) return(object)
normalize.Cel.container.methods <- c(normalize.Cel.container.methods, "nothing")

data(listcel)

listcel.n <- normalize(listcel, method="nothing")
@
%\end{verbatim}

 \subsection{Probe level}

The expression value for an {\it affyID} is derived from the information contained by several probes.
One can obeserve how performs a set of probe pairs for a given {\it affyID}. 
The advantage again is that one can program patterns of analysis. 

The classes verb+PPSet+, verb+PPSet.container+ and verb+Plob+ give acess to the information at the probe level.
Each class has its own methods. The respective help pages will give comprehensive information about them.
We present some of them to demonstrate some of the capabilities

XXX
%>>>LG so... they need to be presented...

 \subsection{Expression values}

The computation of expression values is done from the set of the corresponding probe pairs. The details of
the different approaches suggested will not be detailed here. More details can be found in the help files
for the respective functions.

The general principle is to use the intensities for the probes related to genes on an array in order to
compute (or estimate) the \emph{measured expression value}, reflecting the \emph{true} expression levels of
the genes. The original approach offered by the manufacturer of the arrays is to subtract the mm values to
the corresponding mm, then compute a trimmed\footnote{we believe this is done for robustness. Details can be
found the \emph{Affymetrix} manuals.} average.

There are two \emph{main} ways to obtain expression values. One uses the function \verb+express+ and the
other uses the function \verb+generateExprSet+.
Strictly speaking \verb+generateExprSet+ is a method of the class \verb+Cel.container+. It will compute
expression values from the data contained in the \verb+Cel+ objects. It is the user's responsability to
normalize the data before.

XXX
%>>>LG blablabla

\section{Link with other packages}

This section presents briefly how the package can interact with other packages of {\it bioconductor}.

verb+exprSet+ objects can be generated by the functions verb+express+ and
 verb+generateExprSet+. 

The function \verb+express+ can apply normalization and background adjustment before the computation
of the expression values.

%>>>LG Rafael... tell us about 'express'...

XXX

\section{Scripting steps of the analysis}

\begin{verbatim}
R BATCH < workflow.R
\end{verbatim}


The following lines show what can be written in the file {\it workflow.R}. It performs the complete
workflow described by the manufacturer (with GUI XXX)

Two paths to go from the {\it CEL} and {\it CDF} files to the expression values are suggested. One going through the verb+Plob+ objects and the
other going through the {Cel.container} objects.

XXX
%>>>LG  Rafael.... could you have one for the Plobs ?



\begin{verbatim}

## ------------------
## load the data
## ------------------ 

## GUI ?
CDF <- read.cdffile(XXX)
cels <- read.Cel.container(XXX)


## ------------------
## scale/normalize the data
## ------------------

cels.n <- normalize(cels)

## ------------------
## generate expression values
## ------------------

eset <- generateExprSet(cels.n)

## ------------------
## save the expression values in the exprSet
## ------------------

write.table(exprs(eset), file="flatexpr.txt", sep="\t")

\end{verbatim}

As mentionned earlier, the aim is flexibility rather than speed. The path going through the Plob objects 
can sometimes be faster
% really true ?
while the path going through PPSet.container is more flexible and can integrate easily user defined
functions.

\section{Conclusion - Future developments}

\begin{verbatim}
apply(matrix(1:100, ncol=1),1,cat,"- Laurent needs holydays\n")
\end{verbatim}

\end{document}













